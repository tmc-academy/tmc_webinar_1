{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TMC_WEBINAR_TEST.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1hI_6u49Xm5NZT02lOFDZGlbKraCgAY24",
      "authorship_tag": "ABX9TyO0HO460Z2xQ3kHC6JG6rFL"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e77QP5tx7uEH"
      },
      "source": [
        "![TMC_LOGO](https://docs.google.com/uc?export=download&id=16gkSEgU_fmRg4Jy0_ixMTuzMz0vLffEP)\n",
        "\n",
        "# Let's play with convolutions! \n",
        "#**Build and train a Neural Network in 45 minutes.**\n",
        "#### April 15th, 2021\n",
        "### Daniel Eiroa"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2r45i9ZK8VWd"
      },
      "source": [
        "## Step 0. Getting this notebook ready to work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNRV_QN0_2V_"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Se_szhW8Wib"
      },
      "source": [
        "import os\n",
        "ROOT = os.getcwd()\n",
        "\n",
        "# Fetching and saving pre-trained model\n",
        "!wget --no-check-certificate \"https://docs.google.com/uc?export=download&id=12eo01ukn-B-Sbw2VqYOtSZK8ncNbhmlO\" -O ./results.model\n",
        "RESULTS = os.path.join(ROOT, 'results.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r58DhO7G-pZ-"
      },
      "source": [
        "# Fetching and saving external images, previously unseen by the model\n",
        "!wget --no-check-certificate \"https://docs.google.com/uc?export=download&id=1JdJQu51ci0Yqw9hZMOJi4_5xUjpl23Zv\" -O ./show.zip\n",
        "!unzip -q \"./show.zip\"\n",
        "IMAGES = os.path.join(ROOT, '/show')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0CJwh-k_5NK"
      },
      "source": [
        "### Imports and environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WDTbonF_SJV"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from imutils import paths\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yq8HTgW72U_"
      },
      "source": [
        "## 6️⃣ **Step 6.  Launch the model**\n",
        "\n",
        "Although for this particular instance, the training time was not very long. Depending on our problem, our dataset and our hardware, it may take a while.\n",
        "\n",
        "Good news is we don't have to repeat this process each time we want to predict a new image. We can do so by serializing our model. That means saving only the weights and biases for each of the connections of the NN.\n",
        "\n",
        "Then, when the moment comes, we just need to load this file and apply it to the network, which is ready to predict new images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQD1j7or7wHY"
      },
      "source": [
        "model = load_model(RESULTS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8CPlhp-71fp"
      },
      "source": [
        "for filename in list(paths.list_images(\"/content/drive/MyDrive/Webinar_TMC/show\")):\n",
        "  file = cv2.imread(filename)\n",
        "  img = cv2.cvtColor(file, cv2.COLOR_BGR2RGB) # change the color channels.\n",
        "  img_show = cv2.resize(img, (int(img.shape[1]*0.3), int(img.shape[0]*0.3))) #Reshaping to 40% preserving aspect ratio\n",
        "\n",
        "  img_arr = cv2.resize(img, (224, 224)) # resize the image to 224x224, ignoring aspect ratio.\n",
        "  img_arr = img_to_array(img_arr)\n",
        "  img_arr = np.expand_dims(img_arr, axis=0)\n",
        "  pred = model.predict(img_arr)\n",
        "\n",
        "  test_label = \"COVID\" if pred[0][0]>pred[0][1] else \"Not COVID\"\n",
        "  color = (0, 0, 255) if test_label == \"COVID\" else (0, 255, 0)\n",
        "  test_label = \"{}: {:.2f}%\".format(test_label, max(pred[0][0], pred[0][1]) * 100)\n",
        "\n",
        "  print(str(filename))\n",
        "\n",
        "  cv2.putText(img=img_show, text=test_label, org=(10,30), fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=0.8, color=color, thickness=\n",
        "              2, bottomLeftOrigin=False)\n",
        "  cv2_imshow(img_show)\n",
        "  print('\\n\\n')\n",
        "  cv2.waitKey(1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}